<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cs422 on Jared Rosario</title>
    <link>https://kaonpositive.github.io/tags/cs422/</link>
    <description>Recent content in cs422 on Jared Rosario</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 21 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://kaonpositive.github.io/tags/cs422/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CS 422 Notes 04</title>
      <link>https://kaonpositive.github.io/posts/cs422notes05/</link>
      <pubDate>Thu, 21 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://kaonpositive.github.io/posts/cs422notes05/</guid>
      <description>Random Variables It is a variable that has unknown/random quantity of interest.
${\mathcal X}$: the set of all possible values. Also called a sample space or static space.
Discrete Random Variables Sample space is finite/countably infinite (${\mathcal X}$). Probability of event X = x is denoted by $P(X=x)$ or $P(x)$ for short.
 x: Random Variable (ex: heads/tails) ${\mathcal X}$: Sample Space (ex: S={Heads, Tails}) x (small x) -&amp;gt; x: one of the possible values (ex: x=heads, or x = tails)  Continuous Random Variables If x (a random variable) ${\in\mathbb{R}}$ is a real-valued quantity, it is called a continous random variable.</description>
    </item>
    
    <item>
      <title>CS 422 Notes 04</title>
      <link>https://kaonpositive.github.io/posts/cs422notes04/</link>
      <pubDate>Tue, 19 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://kaonpositive.github.io/posts/cs422notes04/</guid>
      <description>Probability Probability quantifies uncertainty.
 Probability is between 0 and 1.
 P(A): Probability that the event A will occur.
 0 &amp;lt;= P(A) &amp;lt;= 1  P(${A&#39;}$): Probability that the event A will NOT occur.
 $0 &amp;lt;= P({A^c}) &amp;lt;= 1$ $P(A) + P({A^c}) = 1$ $P({A^c}) = 1 - P(A)$  Joint Probability Define probability of two events occuring at the same time. ${P(A \cap B}) = P(A, B)$</description>
    </item>
    
    <item>
      <title>CS 422 Notes 03</title>
      <link>https://kaonpositive.github.io/posts/cs422notes03/</link>
      <pubDate>Thu, 14 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://kaonpositive.github.io/posts/cs422notes03/</guid>
      <description>What is Unsupervised Learning? It is a learning model where it is trained ONLY on the inputs.
 REMEMBER: Supervised learning uses input-output pairs to parameterize the model for improvement.
  Ex of Unsupervised Learning: Music recommendations by using clusters of users that have similar music taste.  What is Clustering? No classification exists to determine data clusters. Therefore, it is a challenge to separate data in their respective classes/groups.</description>
    </item>
    
    <item>
      <title>CS 422 Notes 02</title>
      <link>https://kaonpositive.github.io/posts/cs422notes02/</link>
      <pubDate>Tue, 12 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://kaonpositive.github.io/posts/cs422notes02/</guid>
      <description>$ {y_n} = f({x_n})$ where $f$ is the fuction we assume exist and try to approximate.
$ \hat{y_n} = f^({x_n})$ where $ \hat{y_n} $ is the prediction and $ f^ $ is the model&amp;rsquo;s approximation.
If we try to get comparisons for a data instance, we try to find the best line that fits the data instance the best.
 Ex: you will prefer a function over another function since data is closests to it.</description>
    </item>
    
    <item>
      <title>CS 422 Notes 01</title>
      <link>https://kaonpositive.github.io/posts/cs422notes01/</link>
      <pubDate>Tue, 05 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://kaonpositive.github.io/posts/cs422notes01/</guid>
      <description>Supervised Learning continued&amp;hellip;  x $ {\in} $ X (capital X is the input space) y $ {\in} $ Y (capital Y is the output space)   Basically, the input space is the set of possible inputs; output space is the set of possible outputs.
  D = {(${x_n}, {y_n}$)}${_n}^{N}$ is the set of all input-output pairs.  N is the dataset size and D is script D.</description>
    </item>
    
    <item>
      <title>CS 422 Notes 00</title>
      <link>https://kaonpositive.github.io/posts/cs422notes00/</link>
      <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>https://kaonpositive.github.io/posts/cs422notes00/</guid>
      <description>What is Machine Learning? By definition from Tom Mitchell:
 A computer program is learning form experience E w/ respect to some class of tasks T, and performance measure P, if its performance at tasks in T, as measured by P, improves w/ experience E.
 Breaking it down into simple terms&amp;hellip;
 You improve over tasks T.   Ex: Predicting the price of the house in the market.  W/ repect to some performance P   Ex: How much the house is sold for.</description>
    </item>
    
  </channel>
</rss>
